---
title: |
  | STATS 790 Assignment 3
author: "| Yiran Zhang\n| 400119421\n"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    extra_dependencies: ["amsmath", "amssymb"]
fontsize: 10pt
geometry: margin = 1in
linestretch: 1.5
---

## Question 1
ESL Chapter 5 Figure 5.6 is replicated, the code is shown as below.
```{r, fig.dim=c(8,6)}
# Question 1
# Replicate ESL Chapter 5 Figure 5.6

# Import dataset
bone <- read.table('https://hastie.su.domains/ElemStatLearn/datasets/bone.data', 
                   header = TRUE)

# According to ESL Figure 5.6 description, spnbmd is the target variable
# and age is the predictor.

# Plot the age against relative change in spinal BMD, color separated by gender.
plot(x = bone$age, y = bone$spnbmd, 
     col = ifelse(bone$gender == 'female','red','blue'), 
     pch = 20, xlab = 'Age', ylab = 'Relative Change in Spinal BMD')

# Split male and female.
male_bone <- bone[bone$gender == 'male', ]
female_bone <- bone[bone$gender == 'female', ]

# Spline, using degree of freedom = 12 (given by the textbook)
male_spline <- smooth.spline(x = male_bone$age, y = male_bone$spnbmd, df = 12)
female_spline <- smooth.spline(x = female_bone$age, y = female_bone$spnbmd, df = 12)

# Add splines to the graph with corresponding color for each gender.
lines(male_spline, col = 'blue', lwd = 2)
lines(female_spline, col = 'red', lwd = 2)

# Add a horizontal dash line at y = 0.
abline(h=0, lty=3) 

# Add a legend at the top right corner.
legend(x='topright', legend=c('Male', 'Female'), 
       col=c('blue', 'red'), lwd=2)
```

## Question 2 (South Africa coronary heart disease data)
```{r, warning=FALSE, message=FALSE}
# Question 2
# Import libraries
library(splines)

# Import South Africa coronary heart disease data.
url <- "http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data"
heart <- read.csv(url, row.names = 1)

# Create a list of 5 knots location for the bases
# Knots that can equally divide the tobacco range are chosen
# There are 107 out of 462 tobacco values are 0, 107/462 = 0.2316
# So the first knot need to be greater than 0.2316 to avoid NA values in glm
knots <- quantile(heart$tobacco, probs = c(0.24, 0.32, 0.48, 0.64, 0.8))

# B-spline base
b_spline <- bs(heart$tobacco, knots = knots)

# Natural spline base
n_spline <- ns(heart$tobacco, knots = knots)

# Truncated polynomial base
# Below is the function that creates truncated polynomial spline base
# it is modified based on Dr. Bolker's code
truncpolyspline <- function(x, knots) {
  trunc_fun <- function(k) (x > k)*(x-k)^3
  S <- sapply(knots, trunc_fun)
  S <- cbind(x, x^2, x^3, S)
  return(S)
}

poly_spline <- truncpolyspline(heart$tobacco, knots) # create basis matrix

# Fit logistic regression
# b-spline
logistic_b <- glm(chd ~ b_spline, data = heart, family = 'binomial')
# natural spline
logistic_n <- glm(chd ~ n_spline, data = heart, family = 'binomial')
# truncated polynomial spline
logistic_poly <- glm(chd ~ poly_spline, data = heart, family = 'binomial')

summary(logistic_b)
summary(logistic_n)
summary(logistic_poly)

# Predict without using predict() function on log-odds scale
# b-spline
X_b <- model.matrix(logistic_b) # design matrix for b-spline
coef_b <- as.vector(logistic_b$coefficients) # coefficients vector for b-spline
Y_b <- X_b %*% coef_b # predicted value
var_Y_b <- diag(X_b %*% vcov(logistic_b) %*% t(X_b)) # predicted variance
se_Y_b <- as.matrix(sqrt(var_Y_b)) # predicted se
upper_b <- Y_b + se_Y_b # upper bound of the CI
lower_b <- Y_b - se_Y_b # lower bound of the CI
# Plot the predicted values
plot(heart$tobacco, Y_b, 
     xlab = 'Tobacco consumption', 
     ylab = 'Fitted value in log-odds scale', 
     main = 'B-Spline prediction')
# Upper bound
lines(sort(heart$tobacco), upper_b[order(heart$tobacco)], col = "red", lty = 2)
# Lower bound
lines(sort(heart$tobacco), lower_b[order(heart$tobacco)], col = "red", lty = 2)

# natural spline
X_n <- model.matrix(logistic_n) # design matrix for b-spline
coef_n <- as.vector(logistic_n$coefficients) # coefficients vector for b-spline
Y_n <- X_n %*% coef_n # predicted value
var_Y_n <- diag(X_n %*% vcov(logistic_n) %*% t(X_n)) # predicted variance
se_Y_n <- as.matrix(sqrt(var_Y_n)) # predicted se
upper_n <- Y_n + se_Y_n # upper bound of the CI
lower_n <- Y_n - se_Y_n # lower bound of the CI
# Plot the predicted values
plot(heart$tobacco, Y_n, 
     xlab = 'Tobacco consumption', 
     ylab = 'Fitted value in log-odds scale', 
     main = 'Natural Spline prediction')
# Upper bound
lines(sort(heart$tobacco), upper_n[order(heart$tobacco)], col = "red", lty = 2)
# Lower bound
lines(sort(heart$tobacco), lower_n[order(heart$tobacco)], col = "red", lty = 2)

# truncated polynomial spline
X_poly <- model.matrix(logistic_poly) # design matrix for b-spline
coef_poly <- as.vector(logistic_poly$coefficients) # coefficients vector for b-spline
Y_poly <- X_poly %*% coef_poly # predicted value
var_Y_poly <- diag(X_poly %*% vcov(logistic_poly) %*% t(X_poly)) # predicted variance
se_Y_poly <- as.matrix(sqrt(var_Y_poly)) # predicted se
upper_poly <- Y_poly + se_Y_poly # upper bound of the CI
lower_poly <- Y_poly - se_Y_poly # lower bound of the CI
# Plot the predicted values
plot(heart$tobacco, Y_poly, 
     xlab = 'Tobacco consumption', 
     ylab = 'Fitted value in log-odds scale', 
     main = 'Truncated Polynomial Spline prediction')
# Upper bound
lines(sort(heart$tobacco), upper_poly[order(heart$tobacco)], col = "red", lty = 2)
# Lower bound
lines(sort(heart$tobacco), lower_poly[order(heart$tobacco)], col = "red", lty = 2)
```

## Question 3 (..)

## Question 4 (..)

## Question 5
#### ESL 5.4
The natural boundary conditions for natural cubic splines is that "the function is linear beyond the boundary knots". When X < $\xi_1$, f(x) = $\beta_0 + \beta_1x  + \beta_2x^2 + \beta_3x^3$, to make it linear, we need $\beta_2$ and $\beta_3$ equal to 0. Alternatively, we can prove by taking the second derivative of f(x) and set it to 0. $f''(x) = 2\beta_2+6\beta_3x = 0$, hence $\beta_2 = \beta_3 = 0$.

Similarly, the function f(x) should be linear when X > $\xi_k$ where f(x) = $\beta_0+\beta_1x+\sum_{k=1}^K\theta_k(X-\xi_k)^3$, we take second derivative and set it to 0. $f''(x) = 6\sum_{k=1}^K\theta_k(X-\xi_k) = 6(\sum_{k=1}^K\theta_kX-\sum_{k=1}^K\theta_k\xi_k) = 0$, then we have $\sum_{k=1}^K\theta_kX-\sum_{k=1}^K\theta_k\xi_k = 0$, which implies that $\sum_{k=1}^K\theta_k = 0$ and $\sum_{k=1}^K\theta_k\xi_k = 0$, as required.

Now we derive (5.4) and (5.5). The function we have is $f(x) = \beta_0 + \beta_1x + \sum_{k=1}^K\theta_k(X-\xi_k)_+^3 = 0$, by observing the function, we get that $N_1(X) = 1, N_2(X) = X$, we now want to prove that $\sum_{k=1}^K\theta_k(X-\xi_k)_+^3$ can be written is the form of $N_{k+2}(X) = d_k(X) - d_{k-1}(X)$.

Given that $\sum_{k=1}^K\theta_k = 0$ and $\sum_{k=1}^K\theta_k\xi_k = 0$, we know that $\sum_{k=1}^{K-2}\theta_k = -\theta_K-\theta_{K-1}$ and $\sum_{k=1}^{K-2}\theta_k\xi_k = -\theta_K\xi_K-\theta_{K-1}\xi_{K-1}$.

$\sum_{k=1}^K\theta_k(X-\xi_k)_+^3 = \sum_{k=1}^{K-2}\theta_k(X-\xi_k)_+^3+\theta_{K-1}(X-\xi_{K-1})_+^3+\theta_K(X-\xi_K)_+^3$

\begin{align*}
\theta_{K-1}(X-\xi_{K-1})_+^3 &=\theta_{K-1}(X-\xi_{K-1})_+^3\frac{\xi_{K-1}-\xi_K}{\xi_{K-1}-\xi_K}\\
&= \frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}(\theta_{K-1}\xi_{K-1}-\theta_{K-1}\xi_K)\\ 
&= \frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}(\theta_{K-1}\xi_{K-1}-\theta_{K-1}\xi_K +\theta_K\xi_K - \theta_K\xi_K)\\
&= \frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}(\theta_{K-1}\xi_{K-1}+\theta_K\xi_K - \theta_{K-1}\xi_K - \theta_K\xi_K)\\
&= \frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}(-\sum_{k=1}^{K-2}\theta_k\xi_k+\xi_K\sum_{k=1}^{K-1}\theta_k)\\
&= \frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}\sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)\\
&= \sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)\frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}
\end{align*}

Similarly,
\begin{align*}
\theta_K(X-\xi_K)_+^3 &= \frac{(X-\xi_K)_+^3}{\xi_{K-1}-\xi_K}\theta_K(\xi_{K-1}-\xi_K)\\
&= \frac{(X-\xi_K)_+^3}{\xi_{K-1}-\xi_K}(\theta_K\xi_{K-1}-\theta_K\xi_K+\theta_{K-1}\xi_{K-1}-\theta_{K-1}\xi_{K-1})\\
&= \frac{(X-\xi_K)_+^3}{\xi_{K-1}-\xi_K}(-\xi_{K-1}\sum_{k=1}^{K-2}\theta_K+\sum_{k=1}^{K-2}\theta_k\xi_k)\\
&= \sum_{k=1}^{K-2}\theta_k(\xi_k-\xi_{K-1})\frac{(X-\xi_{K})_+^3}{\xi_{K-1}-\xi_K}
\end{align*}

Put them back together and get:

\begin{align*}
\sum_{k=1}^K\theta_k(X-\xi_k)_+^3 &= \sum_{k=1}^{K-2}\theta_k(X-\xi_k)_+^3+\theta_{K-1}(X-\xi_{K-1})_+^3+\theta_K(X-\xi_K)_+^3\\
&=\sum_{k=1}^{K-2}\theta_k(X-\xi_k)_+^3 + \sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)\frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K} + \sum_{k=1}^{K-2}\theta_k(\xi_k-\xi_{K-1})\frac{(X-\xi_{K})_+^3}{\xi_{K-1}-\xi_K}\\
&= \sum_{k=1}^{K-2}\theta_k [(X-\xi_k)_+^3+(\xi_K-\xi_k)\frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}+(\xi_k-\xi_{K-1})\frac{(X-\xi_{K})_+^3}{\xi_{K-1}-\xi_K}]\\
&= \sum_{k=1}^{K-2}\theta_k[(X-\xi_k)_+^3\frac{\xi_K-\xi_k}{\xi_K-\xi_k}+(\xi_K-\xi_k)\frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}+(\xi_k-\xi_{K-1})\frac{(X-\xi_{K})_+^3}{\xi_{K-1}-\xi_K}\frac{\xi_K-\xi_k}{\xi_K-\xi_k}]\\
&= \sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)[\frac{(X-\xi_k)_+^3}{\xi_K-\xi_k}+\frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}+(\xi_k-\xi_{K-1})\frac{(X-\xi_{K})_+^3}{(\xi_{K-1}-\xi_K)(\xi_K-\xi_k)}]\\
&= \sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)[\frac{(X-\xi_k)_+^3}{\xi_K-\xi_k}+\frac{(X-\xi_{K-1})_+^3}{\xi_{K-1}-\xi_K}+(X-\xi_{K})_+^3(\frac{-1}{\xi_{K-1}-\xi_K}-\frac{1}{\xi_K-\xi_k})]\\
&= \sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)[\frac{(X-\xi_k)_+^3-(X-\xi_{K})_+^3}{\xi_K-\xi_k}+\frac{(X-\xi_{K-1})_+^3-(X-\xi_{K})_+^3}{\xi_{K-1}-\xi_K}]\\
&= \sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)[\frac{(X-\xi_k)_+^3-(X-\xi_{K})_+^3}{\xi_K-\xi_k}-\frac{(X-\xi_{K-1})_+^3-(X-\xi_{K})_+^3}{\xi_K-\xi_{K-1}}]\\
&= \sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)(d_k(X)-d_{K-1}(X))\\
&= \sum_{k=1}^{K-2}\theta_k(\xi_K-\xi_k)N_{k+2}(X)
\end{align*}
Therefore, to conclude, we get $N_1(X) = 1, N_2(X) = X, N_{k+2}(X) = d_k(X)-d_{K-1}(X)$ as desired in (5.4) and (5.5).

#### ESL 5.13
